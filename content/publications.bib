@ARTICLE{automated-capture-experiment-context-for-easier-reproducibility-computational-research,
    author = {Davison A.P.},
    title = {Automated capture of experiment context for easier reproducibility in computational research},
    year = 2012,
    month = {July},
    volume = {14},
    pages = {48--56},
    journal = {Computing in Science and Engineering},
    preprint = {/files/reproducible_research_CiSE.pdf},
    full_text = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2012.41},
    abstract = {Published scientific research that relies on numerical computations is too often not reproducible. For computational research to become consistently and reliably reproducible, the process must become easier to achieve, as part of day-to-day research. A combination of best practices and automated tools can make it easier to create reproducible research.},
}

@INCOLLECTION{biologically-detailed-network-modelling,
    author = {Davison A.P.},
    title = {Biologically-detailed network modelling},
    year = 2004,
    month = {January},
    booktitle = {Computational Neuroscience: A Comprehensive Approach},
    editor = {J. Feng},
    pages = {287--304},
    publisher = {Chapman and Hall/CRC Press},
    address = {Boca Raton},
}

@ARTICLE{biophysical-phenomenological-models-multiple-spike-interactions-spike-timing-dependent-plasticity,
    author = {Badoual M. and Zou Q. and Davison A.P. and Rudolph M. and Bal T. and Frégnac Y. and Destexhe A.},
    title = {Biophysical and phenomenological models of multiple spike interactions in spike-timing dependent plasticity},
    year = 2006,
    month = {April},
    volume = {16},
    pages = {79--97},
    journal = {International Journal of Neural Systems},
    abstract = {Spike-timing dependent plasticity (STDP) is a form of associative synaptic modification which depends on the respective timing of pre- and post-synaptic spikes. The biophysical mechanisms underlying this form of plasticity are currently not known. We present here a biophysical model which captures the characteristics of STDP, such as its frequency dependency, and the effects of spike pair or spike triplet interactions. We also make links with other well-known plasticity rules. A simplified phenomenological model is also derived, which should be useful for fast numerical simulation and analytical investigation of the impact of STDP at the network level},
    model_link = {http://senselab.med.yale.edu/modeldb/ShowModel.asp?model=116096},
}

@ARTICLE{collaborative-modelling-future-computational-neuroscience,
    author = {Davison A.P.},
    title = {Collaborative modelling: the future of computational neuroscience?},
    year = 2012,
    month = {December},
    volume = {23},
    pages = {157--166},
    journal = {Network: Computation in Neural Systems},
    abstract = {Given the complexity of biological neural circuits and of their component cells and synapses, building and simulating robust, well-validated, detailed models increasingly surpasses the resources of an individual researcher or small research group. In this article, I will briefly review possible solutions to this problem, argue for open, collaborative modelling as the optimal solution for advancing neuroscience knowledge, and identify potential bottlenecks and possible solutions.},
    full_text = {http://informahealthcare.com/doi/abs/10.3109/0954898X.2012.718482},
    preprint = {/files/davison_collaborative_modelling_preprint.pdf},
    doi = {10.3109/0954898X.2012.718482}
}

@INCOLLECTION{complexity-neuronal-networks,
    author = {Frégnac Y. and Rudolph M. and Davison A.P. and Destexhe A.},
    title = {Complexity in Neuronal Networks},
    year = 2007,
    month = {December},
    booktitle = {Biological Networks},
    editor = {François Képès},
    pages = {291--338},
    publisher = {World Scientific},
    address = {Singapore},
    book_link = {http://books.google.com/books?id=5pxnNbVs9MMC},
}

@ARTICLE{comprehensive-workflow-for-general-purpose-neural-modeling-with-highly-configurable-neuromorphic-hardware-systems,
    author = {Brüderle D. and Petrovici M.A. and Vogginger B. and Ehrlich M. and Pfeil T. and Millner S. and Grübl A. and Wendt K. and Müller E. and Schwartz M.O. and Husmann de Oliveira D. and Jeltsch S. and Fieres J. and Schilling M. and Müller P. and Breitwieser O. and Petkov V. and Muller L. and Davison A.P. and Krishnamurthy P. and Kremkow J. and Lundqvist M. and Muller E. and Partzsch J. and Scholze S. and Zühl L. and Mayr C. and Destexhe A. and Diesmann M. and Potjans T.C. and Lansner A. and Schüffny R. and Schemmel J. and Meier K.},
    title = {A Comprehensive Workflow for General-Purpose Neural Modeling with Highly Configurable Neuromorphic Hardware Systems},
    year = 2011,
    month = {April},
    volume = {104},
    pages = {263--296},
    journal = {Biological Cybernetics},
    preprint = {http://arxiv.org/abs/1011.2861},
    full_text = {http://www.springerlink.com/openurl.asp?genre=article&id=doi:10.1007/s00422-011-0435-9},
    abstract = {In this paper we present a methodological framework that meets novel requirements emerging from upcoming types of accelerated and highly configurable neuromorphic hardware systems. We describe in detail a device with 45 million programmable and dynamic synapses that is currently under development, and we sketch the conceptual challenges that arise from taking this platform into operation. More specifically, we aim at the establishment of this neuromorphic system as a flexible and neuroscientifically valuable modeling tool that can be used by non-hardware-experts. We consider various functional aspects to be crucial for this purpose, and we introduce a consistent workflow with detailed descriptions of all involved modules that implement the suggested steps: The integration of the hardware interface into the simulator-independent model description language PyNN; a fully automated translation between the PyNN domain and appropriate hardware configurations; an executable specification of the future neuromorphic system that can be seamlessly integrated into this biology-to-hardware mapping process as a test bench for all software layers and possible hardware design modifications; an evaluation scheme that deploys models from a dedicated benchmark library, compares the results generated by virtual or prototype hardware devices with reference software simulations and analyzes the differences. The integration of these components into one hardware-software workflow provides an ecosystem for ongoing preparative studies that support the hardware design process and represents the basis for the maturity of the model-to-hardware mapping software. The functionality and flexibility of the latter is proven with a variety of experimental results.},
}

@ARTICLE{creating-documenting-sharing-network-models,
    author = {Crook S.M. and Bednar J.A. and Berger S. and Cannon R. and Davison A.P. and Djurfeldt M. and Eppler J. and Kriener B. and Furber S. and Graham B. and Plesser H.E. and Schwabe L. and Smith L. and Steuber V. and van Albada S.},
    title = {Creating, documenting and sharing network models.},
    year = 2012,
    month = {December},
    volume = {23},
    pages = {131--149},
    journal = {Network: Computation in Neural Systems},
    abstract = {As computational neuroscience matures, many simulation environments are available
that are useful for neuronal network modeling. However, methods for successfully
documenting models for publication and for exchanging models and model components
among these projects are still under development. Here we briefly review existing
software and applications for network model creation, documentation and exchange.
Then we discuss a few of the larger issues facing the field of computational
neuroscience regarding network modeling and suggest solutions to some of these
problems, concentrating in particular on standardized network model terminology,
notation, and descriptions and explicit documentation of model scaling. We hope this will
enable and encourage computational neuroscientists to share their models more
systematically in the future.},
    full_text = {http://www.tandfonline.com/doi/abs/10.3109/0954898X.2012.722743},
    preprint = {/files/crook_network_pre-review.pdf},
    doi = {10.3109/0954898X.2012.722743}
}

@ARTICLE{dendrodendritic-inhibition-simulated-odor-responses-detailed-olfactory-bulb-network-model,
    author = {Davison A.P. and Feng J. and Brown D.},
    title = {Dendrodendritic inhibition and simulated odor responses in a detailed olfactory bulb network model},
    year = 2003,
    month = {September},
    volume = {90},
    pages = {1921--1935},
    journal = {Journal of Neurophysiology},
    doi = {10.1152/jn.00623.2002},
    full_text = {http://intl-jn.physiology.org/content/90/3/1921.abstract},
    abstract = {In the olfactory bulb both the spatial distribution and the temporal structure of neuronal activity appear to be important for processing odor information, but it is currently impossible to measure both of these simultaneously with high resolution and in all layers of the bulb. We have developed a biologically-realistic model of the mammalian olfactory bulb, incorporating the mitral and granule cells and the dendrodendritic synapses between them, which allows us to observe the network behavior in detail. The cell models were based on previously published work. The attributes of the synapses were obtained from the literature. The pattern of synaptic connections was based on the limited experimental data in the literature on the statistics of connections between neurons in the bulb. The results of simulation experiments with electrical stimulation agree closely in most details with published experimental data. This gives confidence that the model is capturing features of network interactions in the real olfactory bulb. The model predicts that the time course of dendrodendritic inhibition is dependent on the network connectivity as well as on the intrinsic parameters of the synapses. In response to simulated odor stimulation, strongly activated mitral cells tend to suppress neighboring cells, the mitral cells readily synchronize their firing, and increasing the stimulus intensity increases the degree of synchronization. Preliminary experiments suggest that slow temporal changes in the degree of synchronization are more useful in distinguishing between very similar odorants than is the spatial distribution of mean firing},
    model_link = {http://senselab.med.yale.edu/senselab/ModelDB/ShowModel.asp?model=2730},
}

@ARTICLE{efficient-generation-connectivity-neuronal-networks-from-simulator-independent-descriptions,
    author = {Djurfeldt M. and Davison A.P. and Eppler J.M.},
    title = {Efficient generation of connectivity in neuronal networks from simulator-independent descriptions},
    year = 2014,
    month = {March},
    volume = {8:43},
    doi = {10.3389/fninf.2014.00043},
    journal = {Frontiers in Neuroinformatics},
    full_text = {http://journal.frontiersin.org/Journal/10.3389/fninf.2014.00043/abstract},
    abstract = {Simulator-independent descriptions of connectivity in neuronal networks promise greater ease of model sharing, improved reproducibility of simulation results, and reduced programming effort for computational neuroscientists. However, until now, enabling the use of such descriptions in a given simulator in a computationally efficient way has entailed considerable work for simulator developers, which must be repeated for each new connectivity-generating library that is developed.

We have developed a generic connection generator interface that provides a standard way to connect a connectivity-generating library to a simulator, such that one library can easily be replaced by another, according to the modeller's needs. We have used the connection generator interface to connect C++ and Python implementations of the connection-set algebra to the NEST simulator. We also demonstrate how the simulator-independent modelling framework PyNN can transparently take advantage of this, passing a connection description through to the simulator layer for rapid processing in C++ where a simulator supports the connection generator interface and falling-back to slower iteration in Python otherwise. A set of benchmarks demonstrates the good performance of the interface.},
}

@ARTICLE{establishing-novel-modeling-tool-python-based-interface-for-neuromorphic-hardware-system,
    author = {Bruederle D. and Muller E. and Davison A. and Muller E. and Schemmel  J. and Meier K.},
    title = {Establishing a Novel Modeling Tool: A Python-based Interface for a Neuromorphic Hardware System},
    year = 2009,
    month = {May},
    volume = {3:17},
    doi = {10.3389/neuro.11.017.2009},
    full_text = {http://journal.frontiersin.org/article/10.3389/neuro.11.017.2009/abstract},
    journal = {Frontiers in Neuroinformatics},
    abstract = {Neuromorphic hardware systems provide new possibilities for the neuroscience modeling community. Due to the intrinsic parallelism of the micro-electronic emulation of neural computation, such models are highly scalable without a loss of speed. However, the communities of software simulator users and neuromorphic engineering in neuroscience are rather disjoint. We present a software concept that provides the possibility to establish such hardware devices as valuable modeling tools. It is based on the integration of the hardware interface into a simulator-independent language which allows for unified experiment descriptions that can be run on various simulation platforms without modification, implying experiment portability and a huge simplification of the quantitative comparison of hardware and simulator results. We introduce an accelerated neuromorphic hardware device and describe the implementation of the proposed concept for this system. An example setup and results acquired by utilizing both the hardware system and a software simulator are demonstrated.},
}

@ARTICLE{integrated-workflows-for-spiking-neuronal-network-simulations,
    author = {Antolík J. and Davison A.P.},
    title = {Integrated workflows for spiking neuronal network simulations},
    year = 2013,
    month = {November},
    volume = {7:34},
    doi = {10.3389/fninf.2013.00034},
    journal = {Frontiers in Neuroinformatics},
    full_text = {http://www.frontiersin.org/neuroinformatics/10.3389/fninf.2013.00034/abstract},
    abstract = {The increasing availability of computational resources is enabling more detailed, realistic modelling in computational neuroscience, resulting in a shift towards more heterogeneous models of neuronal circuits, and employment of complex experimental protocols. This poses a challenge for existing tool chains, as the set of tools involved in a typical modeller's workflow is expanding concomitantly, with growing complexity in the metadata flowing between them. For many parts of the workflow, a range of tools is available; however, numerous areas lack dedicated tools, while integration of existing tools is limited. This forces modellers to either handle the workflow manually, leading to errors, or to write substantial amounts of code to automate parts of the workflow, in both cases reducing their productivity. To address these issues, we have developed Mozaik: a workflow system for spiking neuronal network simulations written in Python. Mozaik integrates model, experiment and stimulation specification, simulation execution, data storage, data analysis and visualisation into a single automated workflow, ensuring that all relevant metadata are available to all workflow components. It is based on several existing tools, including PyNN, Neo and Matplotlib. It offers a declarative way to specify models and recording configurations using hierarchically organised configuration files. Mozaik automatically records all data together with all relevant metadata about the experimental context, allowing automation of the analysis and visualisation stages. Mozaik has a modular architecture, and the existing modules are designed to be extensible with minimal programming effort. Mozaik increases the productivity of running virtual experiments on highly structured neuronal networks by automating the entire experimental cycle, while increasing the reliability of modelling studies by relieving the user from manual handling of the flow of metadata between the individual workflow stages.},
}

@ARTICLE{learning-crossmodal-spatial-transformations-through-spike-timing-dependent-plasticity,
    author = {Davison A.P. and Frégnac Y.},
    title = {Learning crossmodal spatial transformations through spike-timing-dependent plasticity},
    year = 2006,
    month = {May},
    volume = {26},
    pages = {5604--5615},
    journal = {The Journal of Neuroscience},
    model_link = {http://senselab.med.yale.edu/senselab/ModelDB/ShowModel.asp?model=64261},
    abstract = {A common problem in tasks involving the integration of spatial information from multiple senses, or in sensorimotor coordination, is that different modalities represent space in different frames of reference. Coordinate transformations between different reference frames are therefore required. One way to achieve this relies on the encoding of spatial information with population codes. The set of network responses to stimuli in different locations (tuning curves) constitutes a set of basis functions that can be combined linearly through weighted synaptic connections to approximate nonlinear transformations of the input variables. The question then arises: how is the appropriate synaptic connectivity obtained? Here we show that a network of spiking neurons can learn the coordinate transformation from one frame of reference to another, with connectivity that develops continuously in an unsupervised manner, based only on the correlations available in the environment and with a biologically realistic plasticity mechanism (spike timing-dependent plasticity)},
}

@INCOLLECTION{learning-from-past-approaches-for-reproducibility-computational-neuroscience,
    author = {Crook S.M and Davison A.P. and Plesser H.E.},
    title = {Learning from the past: approaches for reproducibility in computational neuroscience},
    year = 2013,
    month = {July},
    booktitle = {20 Years of Computational Neuroscience},
    editor = {J.M. Bower},
    pages = {73--102},
    publisher = {Springer},
    address = {New York}
}

@ARTICLE{libneuroml-pylems-using-python-to-combine-procedural-declarative-modelling-approaches-computational-neuroscience,
    author = {Vella M. and  Cannon R.C. and Crook S. and  Davison A.P. and  Ganapathy G. and  Robinson H.P.C. and Silver R.A. and Gleeson P.},
    title = {libNeuroML and PyLEMS: using Python to combine procedural and declarative modelling approaches in computational neuroscience},
    year = 2014,
    month = {March},
    volume = {8:38},
    doi = {10.3389/fninf.2014.00038},
    journal = {Frontiers in Neuroinformatics},
    abstract = {NeuroML is an XML-based model description language, which provides a powerful common data format for defining and exchanging models of neurons and neuronal networks. In the latest version of NeuroML, the structure and behavior of ion channel, synapse, cell, and network model descriptions are based on underlying definitions provided in LEMS, a domain-independent language for expressing hierarchical mathematical models of physical entities. While declarative approaches for describing models have led to greater exchange of model elements among software tools in computational neuroscience, a frequent criticism of XML-based languages is that they are difficult to work with directly. Here we describe two Application Programming Interfaces (APIs) written in Python (http://www.python.org), which simplify the process of developing and modifying models expressed in NeuroML and LEMS. The libNeuroML API provides a Python object model with a direct mapping to all NeuroML concepts defined by the NeuroML Schema, which facilitates reading and writing the XML equivalents. In addition, it offers a memory-efficient, array-based internal representation, which is useful for handling large-scale connectomics data. The libNeuroML API also includes support for performing common operations that are required when working with NeuroML documents. Access to the LEMS data model is provided by the PyLEMS API, which provides a Python implementation of the LEMS language, including the ability to simulate most models expressed in LEMS. Together, libNeuroML and PyLEMS provide a comprehensive solution for interacting with NeuroML models in a Python environment.},
    full_text = {http://journal.frontiersin.org/Journal/10.3389/fninf.2014.00038/abstract}
}


@INCOLLECTION{modeldb-resource-for-neuronal-network-modeling,
    author = {Davison A.P. and Morse T.M. and Migliore M. and Marenco L. and Shepherd G.M. and Hines M.L.},
    title = {ModelDB: A Resource for Neuronal and Network Modeling},
    year = 2002,
    month = {January},
    booktitle = {Neuroscience Databases: A Practical Guide},
    editor = {R. Kötter},
    pages = {99--109},
    publisher = {Kluwer Academic Publishers},
    address = {Norwell, MA},
    abstract = {ModelDB is an online database (<a href="http://senselab.med.yale.edu/senselab/ModelDB">senselab.med.yale.edu/senselab/ModelDB</a>) of published neuronal models, including models of ion channels, dendrites, axons, neurons, synapses and networks of neurons. Having ready access to the code for a model facilitates testing and verification of a model, re-use of model components to speed development of new models, and comparing a model to new experimental data. The database is useful for archiving models and for collaboration on modeling projects, and is a resource for teachers and students in both theoretical and experimental neuroscience. We describe here how to use the database: how to find specific models, how to obtain model code, how to run models, and how to contribute a model to the database,}
}

@ARTICLE{neo-an-object-model-for-handling-electrophysiology-data-multiple-formats,
    author = {Garcia S. and Guarino D. and Jaillet F. and Jennings T.R. and Pröpper R. and Rautenberg P.L. and Rodgers C. and Sobolev A. and Wachtler T. and Yger P. and Davison A.P.},
    title = {Neo: an object model for handling electrophysiology data in multiple formats},
    year = 2014,
    month = {February},
    volume = {8:10},
    doi = {10.3389/fninf.2014.00010},
    journal = {Frontiers in Neuroinformatics},
    full_text = {http://www.frontiersin.org/Journal/10.3389/fninf.2014.00010/abstract},
    abstract = {Neuroscientists use many different software tools to acquire, analyse and visualise electrophysiological signals.
However, incompatible data models and file formats make it difficult to exchange data between these tools.
This reduces scientific productivity, renders potentially useful analysis methods inaccessible and impedes collaboration between labs.
A common representation of the core data would improve interoperability and facilitate data-sharing.
To that end, we propose here a language-independent object model, named ``Neo'', suitable for representing data acquired from electroencephalographic, intracellular, or extracellular recordings, or generated from simulations.
As a concrete instantiation of this object model we have developed an open source implementation in the Python programming language.
In addition to representing electrophysiology data in memory for the purposes of analysis and visualisation, the Python implementation provides a set of input/output (IO) modules for reading/writing the data from/to a variety of commonly used file formats.
Support is included for formats produced by most of the major manufacturers of electrophysiology recording equipment and also for more generic formats such as MATLAB.
Data representation and data analysis are conceptually separate: it is easier to write robust analysis code if it is focused on analysis and relies on an underlying package to handle data representation.
For that reason, and also to be as lightweight as possible, the Neo object model and the associated Python package are deliberately limited to representation of data, with no functions for data analysis or visualisation.
Software for neurophysiology data analysis and visualisation built on top of Neo automatically gains the benefits of interoperability, easier data sharing and automatic format conversion; there is already a burgeoning ecosystem of such tools.
We intend that Neo should become the standard basis for Python tools in neurophysiology.},
}

@ARTICLE{neuroml-language-for-describing-data-driven-models-neurons-networks-with-high-degree-biological-detail,
    author = {Gleeson P. and Crook S. and Cannon R.C. and Hines M.L. and Billings and G.O. and Farinella M. and Morse T.M. and Davison A.P. and Ray S. and Bhalla U.S. and Barnes S.R. and Dimitrova Y.D. and Silver and R.A.},
    title = {NeuroML: A language for describing data driven models of neurons and networks with a high degree of biological detail},
    year = 2010,
    month = {June},
    volume = {6},
    pages = {e1000815},
    journal = {PLoS Computational Biology},
    doi = {10.1371/journal.pcbi.1000815},
    full_text = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000815},
    abstract = {Computer modeling is becoming an increasingly valuable tool in the study of the complex interactions underlying the behavior of the brain. Software applications have been developed which make it easier to create models of neural networks as well as detailed models which replicate the electrical activity of individual neurons. The code formats used by each of these applications are generally incompatible however, making it difficult to exchange models and ideas between researchers. Here we present the structure of a neuronal model description language, NeuroML. This provides a way to express these complex models in a common format based on the underlying physiology, allowing them to be mapped to multiple applications. We have tested this language by converting published neuronal models to NeuroML format and comparing their behavior on a number of commonly used simulators. Creating a common, accessible model description format will expose more of the model details to the wider neuroscience community, thus increasing their quality and reliability, as for other Open Source software. NeuroML will also allow a greater “ecosystem” of tools to be developed for building, simulating and analyzing these complex neuronal systems.},
}

@ARTICLE{neuron-python,
    author = {Hines M.L. and Davison A.P. and Muller E.},
    title = {NEURON and Python},
    year = 2009,
    month = {January},
    volume = {3:1},
    doi = {10.3389/neuro.11.001.2009},
    full_text = {http://journal.frontiersin.org/article/10.3389/neuro.11.001.2009/abstract},
    journal = {Frontiers in Neuroinformatics},
    abstract = {The NEURON simulation program now allows Python to be used, alone or in combination with NEURON's traditional Hoc interpreter. Adding Python to NEURON has the immediate benefit of making available a very extensive suite of analysis tools written for engineering and science. It also catalyzes NEURON software development by offering users a modern programming tool that is recognized for its flexibility and power to create and maintain complex programs. At the same time, nothing is lost because all existing models written in Hoc, including GUI tools, continue to work without change and are also available within the Python context. An example of the benefits of Python availability is the use of the XML module in implementing NEURON's Import3D and CellBuild tools to read MorphML and NeuroML model specifications. },
}

@INCOLLECTION{nineml,
    author = {Davison A.P.},
    title = {NineML},
    year = 2013,
    month = {October},
    booktitle = {Encyclopedia of Computational Neuroscience: SpringerReference},
    editor = {Jaeger D. and Jung R.},
    pages = {-},
    publisher = {Springer-Verlag},
    address = {Berlin Heidelberg},
    full_text = {https://doi.org/10.1007/978-1-4614-7320-6_375-2},
    doi = {10.1007/978-1-4614-7320-6_375-2},
}

@INCOLLECTION{olfactory-bulb,
    author = {Davison A.P. and Shepherd G.M.},
    title = {Olfactory Bulb},
    year = 2002,
    month = {January},
    booktitle = {The Handbook of Brain Theory and Neural Networks, 2nd Edn},
    editor = {M. Arbib},
    pages = {},
    publisher = {The MIT Press},
    address = {Cambridge, MA},
    abstract = {},
}

@ARTICLE{pynn-common-interface-for-neuronal-network-simulators,
    author = {Davison A.P. and Brüderle D. and Eppler J.M. and Kremkow and J. and Muller E. and Pecevski D.A. and Perrinet L. and Yger P.},
    title = {PyNN: a common interface for neuronal network simulators},
    year = 2009,
    month = {January},
    volume = {2:11},
    doi = {10.3389/neuro.11.011.2008},
    full_text = {http://journal.frontiersin.org/article/10.3389/neuro.11.011.2008/abstract},
    journal = {Frontiers in Neuroinformatics},
    abstract = {Computational neuroscience has produced a diversity of software for simulations of networks of spiking neurons, with both negative and positive consequences. On the one hand, each simulator uses its own programming or configuration language, leading to considerable difficulty in porting models from one simulator to another. This impedes communication between investigators and makes it harder to reproduce and build on the work of others. On the other hand, simulation results can be cross-checked between different simulators, giving greater confidence in their correctness, and each simulator has different optimizations, so the most appropriate simulator can be chosen for a given modelling task. A common programming interface to multiple simulators would reduce or eliminate the problems of simulator diversity while retaining the benefits. PyNN is such an interface, making it possible to write a simulation script once, using the Python programming language, and run it without modification on any supported simulator (currently NEURON, NEST, PCSIM, Brian and the Heidelberg VLSI neuromorphic hardware). PyNN increases the productivity of neuronal network modelling by providing high-level abstraction, by promoting code sharing and reuse, and by providing a foundation for simulator-agnostic analysis, visualization, and data-management tools. PyNN increases the reliability of modelling studies by making it much easier to check results on multiple simulators. PyNN is open-source software and is available from http://neuralensemble.org/PyNN.},
}

@INCOLLECTION{pynn-python-api-for-neural-network-modelling,
    author = {Davison A.P.},
    title = {PyNN: a Python API for Neural Network Modelling},
    month = {July},
    year = 2013,
    booktitle = {Encyclopedia of Computational Neuroscience: SpringerReference},
    editor = {D. Jaeger and R. Jung},
    pages = {-},
    publisher = {Springer-Verlag},
    address = {Berlin Heidelberg},
    doi = {10.1007/978-1-4614-7320-6_261-5},
    full_text = {https://doi.org/10.1007/978-1-4614-7320-6_261-5},
}

@ARTICLE{reduced-compartmental-model-mitral-cell-for-use-network-models-olfactory-bulb,
    author = {Davison A.P. and Feng J. and Brown D.},
    title = {A reduced compartmental model of the mitral cell for use in network models of the olfactory bulb},
    year = 2000,
    month = {March},
    volume = {51},
    pages = {393--399},
    doi = {10.1016/S0361-9230(99)00256-7},
    journal = {Brain Research Bulletin},
    abstract = {We have developed two-, three- and four-compartment models of a mammalian olfactory bulb mitral cell as a reduction of a complex 286-compartment model. A minimum of three compartments, representing soma, secondary (basal) dendrites and the glomerular tuft of the primary dendrite, is required to adequately reproduce the behaviour of the full model over a broad range of firing rates. Adding a fourth compartment to represent the shaft of the primary dendrite gives a substantial improvement. The reduced models exhibit behaviours in common with the full model which were not used in fitting the model parameters. The reduced models run 75 or more times faster than the full model, making their use in large, realistic network models of the olfactory bulb practical},
    model_link = {http://senselab.med.yale.edu/senselab/ModelDB/ShowModel.asp?model=2487},
}

@ARTICLE{reliable-recall-spontaneous-activity-patterns-cortical-networks,
    author = {Marre O. and Yger P. and Davison A.P. and Frégnac Y.},
    title = {Reliable recall of spontaneous activity patterns in cortical networks},
    year = 2009,
    month = {November},
    volume = {29},
    pages = {14596--14606},
    journal = {The Journal of Neuroscience},
    abstract = {Irregular ongoing activity in cortical networks is often modeled as arising from recurrent connectivity. Yet it remains unclear to what
extent its presence corrupts sensory signal transmission and network computational capabilities. In a recurrent cortical-like network, we
have determined the activity patterns that are better transmitted and self-sustained by the network. We show that reproducible spiking
and subthreshold dynamics can be triggered if the statistics of the imposed external drive are consistent with patterns previously seen in
the ongoing activity. A subset of neurons in the network, constrained to replay temporal pattern segments extracted from the recorded
ongoing activity of the same network, reliably drives the remaining, free-running neurons to call the rest of the pattern. Comparison with
surrogate Poisson patterns indicates that the efficiency of the recall and completion process depends on the similarity between the
statistical properties of the input with previous ongoing activity The reliability of evoked dynamics in recurrent networks is thus
dependent on the stimulus used, and we propose that the similarity between spontaneous and evoked activity in sensory cortical areas
could be a signature of efficient transmission and propagation across cortical networks},
}

@ARTICLE{simulation-networks-spiking-neurons-review-tools-strategies,
    author = {R. Brette and 21 others},
    title = {Simulation of networks of spiking neurons: A review of tools and strategies},
    year = 2007,
    month = {December},
    volume = {23},
    pages = {349--398},
    preprint = {http://arxiv.org/abs/q-bio/0611089v2},
    model_link = {http://senselab.med.yale.edu/senselab/ModelDB/ShowModel.asp?model=83319},
    journal = {Journal of Computational Neuroscience},
    abstract = {We review different aspects of the simulation of spiking neural networks. We start by reviewing the different types of simulation strategies and algorithms that are currently implemented. We next review the precision of those simulation strategies, in particular in cases where plasticity depends on the exact timing of the spikes. We overview different simulators and simulation environments presently available (restricted to those freely available, open source and documented). For each simulation tool, its advantages and pitfalls are reviewed, with an aim to allow the reader to identify which simulator is appropriate for a given task. Finally, we provide a series of benchmark simulations of different types of networks of spiking neurons, including Hodgkin-Huxley type, integrate-and-fire models, interacting with current-based or conductance-based synapses, using clock-driven or event-driven integration strategies. The same set of models are implemented on the different simulators, and the codes are made available. The ultimate goal of this review is to provide a resource to facilitate identifying the appropriate integration strategy and simulation tool to use for a given modeling problem related to spiking neural networks.},
}

@INCOLLECTION{sumatra-toolkit-for-reproducible-research,
    author = {Davison A.P. and Mattioni M. and Samarkanov D. and Teleńczuk B. },
    title = {Sumatra: A Toolkit for Reproducible Research},
    year = 2014,
    month = {March},
    booktitle = {Implementing Reproducible Research},
    editor = {V. Stodden and F. Leisch and R.D. Peng},
    pages = {57--79},
    publisher = {Chapman &amp; Hall/CRC},
    address = {Boca Raton, Florida.},
    full_text = {https://osf.io/w6fp4/osffiles/Andrew_Davison_chapter.pdf/version/1/download/},
    book_link = {http://www.amazon.com/Implementing-Reproducible-Research-Chapman-Series/dp/1466561599}
}

@ARTICLE{trends-programming-languages-for-neuroscience-simulations,
    author = {Davison A.P. and Hines M. and Muller E.},
    title = {Trends in programming languages for neuroscience simulations},
    year = 2009,
    month = {December},
    volume = {3:3},
    doi = {10.3389/neuro.01.036.2009},
    full_text = {http://journal.frontiersin.org/article/10.3389/neuro.01.036.2009/abstract},
    journal = {Frontiers in Neuroscience},
    abstract = {Neuroscience simulators allow scientists to express models in terms of biological concepts, without having to concern themselves with low-level computational details of their implementation. The expressiveness, power and ease-of-use of the simulator interface is critical in efficiently and accurately translating ideas into a working simulation. We review long-term trends in the development of programmable simulator interfaces, and examine the benefits of moving from proprietary, domain-specific languages to modern dynamic general-purpose languages, in particular Python, which provide neuroscientists with an interactive and expressive simulation development environment and easy access to state-of-the-art general-purpose tools for scientific computing.},
}

@PHDTHESIS{davison-phd,
    author = {Davison A.P.},
    year = 2001,
    title = {Mathematical modelling of information processing in the olfactory bulb},
    school = {University of Cambridge},
    month = {March},
    abstract = {The aim of this dissertation is to investigate the processing of sensory signals in the mammalian olfactory bulb, using analysis and computer simulation of mathematical models. A biologically-detailed mathematical model provides a framework which integrates the results of experiments at different levels of enquiry, and enables study of problems which cannot easily be addressed using only the methods of experimental neuroscience.
Specific biological and computational problems which are addressed include: the existence, origin and role of oscillations/synchronisation; how the properties of individual cells/synapses influence the network behaviour; the role of lateral inhibition; how the connectivity between cells influences network behaviour.
The dissertation has four main parts: (i) a review of the anatomy and physiology of vertebrate olfactory systems, and of previous modelling studies of the olfactory bulb; (ii) development of biophysical models of the principal neurone types of the olfactory bulb, based closely on experimental data, but simple enough to allow simulation of large networks; (iii) an examination of the fundamental interaction in the bulb -- that between two mitral cells -- using simulation of the biophysical cell models and analysis of the simpler integrate-and-fire neurone model; (iv) development of network models of the olfactory bulb incorporating the biophysical neurone models. These are tested using experimental data from the literature, and then the properties of the network are studied, leading to predictions which could be tested experimentally.},
    full_text = {/files/davison_thesis.pdf}
}

@ARTICLE{la-recherche-reproductible-une-communication-scientifique-explicite,
    author = {Pouzat C. and Davison A. and Hinsen K.},
    title = {La recherche reproductible : une communication scientifique explicite},
    year = 2015,
    month = {June},
    volume = {3},
    pages = {35--38},
    journal = {Statistique et société},
    abstract = {Dans les articles de recherche ordinaires, tout n’est pas écrit, loin de là : des connaissances sont présupposées, des détails techniques sont omis. Depuis quelques années, des chercheurs ont entrepris de publier des articles qui, en plus du contenu scientifique classique, contiennent toute l’information nécessaire à la reproduction de celui-ci, une fois les données acquises. Des logiciels spécifiques ont été mis au point pour rendre aisée la production de tels articles. Les chercheurs ont intérêt à en profiter, car les revues scientifiques et les agences de financement de la recherche leur demandent de plus en plus d’adopter ce genre de pratiques.},
}

@ARTICLE{python-in-neuroscience,
	author = {Muller E. and Bednar J.A. and Diesmann M. and Gewaltig M.-O. and Hines M. and Davison A.P.},
	doi = {10.3389/fninf.2015.00011},
	issn = {1662-5196},
	journal = {Frontiers in Neuroinformatics},
	number = {11},
	title = {Python in Neuroscience},
	url = {http://www.frontiersin.org/neuroinformatics/10.3389/fninf.2015.00011/full},
	volume = {9},
	year = 2015,
	month = {April}
}

@INCOLLECTION{collaborative-simulation-analysis-workflow,
    author = {Senk J. and Yegenoglu A. and Amblet O. and Brukau Y. and Davison A. and Lester D.R. and Lührs A. and Quaglio P. and Rostami V. and Rowley A. and Schuller B. and Stokes A.B. and van Albada S.J. and Zielasko D. and Diesmann M. and Weyers B. and Denker M. and Grün S.},
    year = 2017,
    month = {February},
    title = {A Collaborative Simulation-Analysis Workflow for Computational Neuroscience Using HPC},
    editor = {Di Napoli E., Hermanns MA., Iliev H., Lintermann A., Peyser A.},
    booktitle = {High-Performance Scientific Computing. JHPCS 2016. Lecture Notes in Computer Science},
    volume = {10164},
    publisher = {Springer},
    doi = {10.1007/978-3-319-53862-4_21}
}

@ARTICLE{towards-standard-practices-sharing,
    author = {Eglen S.J. and Marwick B. and Halchenko Y.O. and Hanke M. and Sufi S. and Gleeson P. and Silver A.R. and Davison A.P. and Lanyon L. and Abrams M. and Wachtler T. and Willshaw D.J. and Pouzat C. and Poline J.-B.},
    year = 2017,
    month = {May},
    title = {Toward standard practices for sharing computer code and programs in neuroscience},
    journal = {Nature Neuroscience},
    volume = 20,
    pages = {770--773},
    doi = {10.1038/nn.4550}
}

@ARTICLE{sustainable-computational-science,
    author = {Rougier N.P. and Hinsen K. and Alexandre F. and Arildsen T. and Barba L. and Benureau F.C.Y. and Brown C.T. and de Buyl P. and Caglayan O. and Davison A.P. and Delsuc M.A. and Detorakis G. and Diem A.K. and Drix D. and Enel P. and Girard B. and Guest O. and Hall M.G. and Henriques R.N. and Hinaut X. and Jaron K.S. and Khamassi M. and Klein A. and Manninen T. and Marchesi P. and McGlinn D. and Metzner C. and Petchey O.L. and Plesser H.E. and Poisot T. and Ram K. and Ram Y. and Roesch E. and Rossant C. and Rostami V. and Shifman A. and Stachelek J. and Stimberg M. and Stollmeier F. and Vaggi F. and Viejo G. and Vitay J. and Vostinar A. and Yurchak R. and Zito T.},
    year = 2017,
    month = {December},
    journal = {PeerJ Computer Science},
    volume = 3,
    pages = {e142},
    doi = {doi.org/10.7717/peerj-cs.142},
    title = {Sustainable computational science: the ReScience initiative},
    full_text = {https://peerj.com/articles/cs-142/},
    preprint = {https://arxiv.org/abs/1707.04393}
}

@ARTICLE{open-source-neuroscience,
    author = {Gleeson P. and Davison A.P. and Silver R.A. and Ascoli G.A},
    title = {A commitment to open source in neuroscience},
    journal = {Neuron},
    volume = 96,
    year = 2017,
    month = {December},
    pages = {964--965},
    doi = {10.1016/j.neuron.2017.10.013},
    full_text = {http://www.sciencedirect.com/science/article/pii/S0896627317309819/pdfft?md5=08ded6dde4e4d472865f4d1985df40ca&pid=1-s2.0-S0896627317309819-main.pdf},
    open_letter = {http://www.opensourceforneuroscience.org/}
}

@ARTICLE{arkheia,
    author = {Antolík J. and Davison A.P.},
    title = {Arkheia: data management and communication for open computational neuroscience},
    journal = {Frontiers in Neuroinformatics},
    volume = {12},
    number = {6},
    year = 2018,
    month = {March},
    doi = {10.3389/fninf.2018.00006},
    full_text = {https://www.frontiersin.org/articles/10.3389/fninf.2018.00006/abstract}
}

@ARTICLE{codegen,
    author = {Blundell I. and Brette R. and Cleland T.A. and Close T.G. and Coca D. and Davison A.P. and Diaz-Pier S. and Musoles C.F. and Gleeson P. and Goodman D.F. and Hines M. and Hopkins M.W. and Kumbhar P. and Lester D.R. and Marin B. and Morrison A. and Müller E. and  Nowotny T. and Peyser A. and Plotnikov D. and Richmond P. and Rowley A. and Rumpe B. and Stimberg M. and Stokes A.B. and Tomkins A. and Trensch G. and Woodman M. and Eppler J.M.},
    title = {Code generation in computational neuroscience: a review of tools and techniques},
    journal = {Frontiers in Neuroinformatics},
    volume = 12,
    number = 68,
    year = 2018,
    month = {November},
    doi = {10.3389/fninf.2018.00068},
    full_text = {https://doi.org/10.3389/fninf.2018.00068}
}

@ARTICLE{osb,
    author = {Gleeson P. and Cantarelli M. and Marin B. and Quintana A. and Earnshaw M. and Sadeh S. and Piasini E. and Birgiolas J. and Cannon R.C. and Cayco-Gajic N.A. and Crook S. and Davison A.P. and Dura-Bernal S. and Ecker A. and Hines M.L. and Idili G. and Lanore F. and Larson S.D. and Lytton W.W. and Majumdar A. and McDougal R.A. and Sivagnanam S. and Solinas S. and Stanislovas R. and van Albada S.J. and van Geit W. and Silver R.A.},
    title = {Open Source Brain: A Collaborative Resource for Visualizing, Analyzing, Simulating, and Developing Standardized Models of Neurons and Circuits},
    journal = {Neuron},
    year = 2019,
    month = {June},
    doi = {10.1016/j.neuron.2019.05.019},
    full_text = {https://doi.org/10.1016/j.neuron.2019.05.019}
}
